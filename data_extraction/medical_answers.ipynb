{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548d2a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from datasets import Dataset, ClassLabel\n",
    "from datasets import load_from_disk\n",
    "\n",
    "from llm_mri import ActivationAreas\n",
    "from llm_mri.dimensionality_reduction import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891be113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "medical_answers_path = \"../datasets/medical_answers/\"\n",
    "\n",
    "df_dpoc = pd.read_excel(\n",
    "    medical_answers_path + \"Resultados_Anotacoes_Teste_Progresso-DPOC-Fernando.xlsx\"\n",
    ")\n",
    "df_iam = pd.read_excel(\n",
    "    medical_answers_path + \"Resultados_Anotacoes_Teste_Progresso-IAM-Fernando.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94117cda",
   "metadata": {},
   "source": [
    "# Original Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b8923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dpoc rows (included in analysis): 432\n",
      "df_iam rows (included in analysis): 447\n"
     ]
    }
   ],
   "source": [
    "# Display the length of each DataFrame\n",
    "def get_dataframe_len(df_dpoc, df_iam):\n",
    "    if \"include_in_analysis\" in df_dpoc.columns:\n",
    "        df_dpoc_filtered = df_dpoc[df_dpoc[\"include_in_analysis\"] == True]\n",
    "        print(\"df_dpoc rows (included in analysis):\", len(df_dpoc_filtered))\n",
    "    else:\n",
    "        print(\"df_dpoc rows:\", len(df_dpoc))\n",
    "\n",
    "\n",
    "    if \"include_in_analysis\" in df_iam.columns:\n",
    "        df_iam_filtered = df_iam[df_iam[\"include_in_analysis\"] == True]\n",
    "        print(\"df_iam rows (included in analysis):\", len(df_iam_filtered))\n",
    "    else:\n",
    "        print(\"df_iam rows:\", len(df_iam))\n",
    "\n",
    "get_dataframe_len(df_dpoc, df_iam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34aacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the target columns\n",
    "\n",
    "# user id ==> identificador único do aluno\n",
    "# objective test score ==> nota obtida pelos alunos no OSCE (Objective Structured Clinical Examination)\n",
    "# question 2, question ==> resposta da questão dissertativa\n",
    "# global score ==> nota global dada à resposta\n",
    "\n",
    "# target_columns_dpoc = [\"user id\", \"objective test score\", \"question 2\", \"global score\"]\n",
    "# target_columns_iam = [\"user id\", \"objective test score\", \"question\", \"global score\"]\n",
    "\n",
    "# df_dpoc = df_dpoc[target_columns_dpoc]\n",
    "# df_iam = df_iam[target_columns_iam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94bcf56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dpoc rows (included in analysis): 432\n",
      "df_iam rows (included in analysis): 447\n"
     ]
    }
   ],
   "source": [
    "# Add a new column to mark usable rows\n",
    "# Add a new column to mark usable rows\n",
    "df_dpoc['include_in_analysis'] = (~df_dpoc[['question 2', 'global score']].isnull().any(axis=1)).astype(int)\n",
    "df_iam['include_in_analysis'] = (~df_iam[['question', 'global score']].isnull().any(axis=1)).astype(int)\n",
    "\n",
    "get_dataframe_len(df_dpoc, df_iam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be87370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dpoc rows (included in analysis): 432\n",
      "df_iam rows (included in analysis): 447\n"
     ]
    }
   ],
   "source": [
    "# Mark duplicates by \"user id\"\n",
    "dup_mask_dpoc = df_dpoc.duplicated(subset=[\"user id\"], keep=\"first\")\n",
    "dup_mask_iam = df_iam.duplicated(subset=[\"user id\"], keep=\"first\")\n",
    "\n",
    "df_dpoc.loc[dup_mask_dpoc, \"include_in_analysis\"] = 0\n",
    "df_iam.loc[dup_mask_iam, \"include_in_analysis\"] = 0\n",
    "\n",
    "get_dataframe_len(df_dpoc, df_iam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bffd3b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dpoc rows (included in analysis): 432\n",
      "df_iam rows (included in analysis): 447\n"
     ]
    }
   ],
   "source": [
    "# Mark duplicates based on answers column\n",
    "dup_mask_dpoc_answers = df_dpoc.duplicated(subset=[\"question 2\"], keep=\"first\")\n",
    "dup_mask_iam_answers = df_iam.duplicated(subset=[\"question\"], keep=\"first\") \n",
    "\n",
    "df_dpoc.loc[dup_mask_dpoc_answers, \"include_in_analysis\"] = 0\n",
    "df_iam.loc[dup_mask_iam_answers, \"include_in_analysis\"] = 0\n",
    "get_dataframe_len(df_dpoc, df_iam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c96c3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save new column to excel files\n",
    "# df_dpoc.to_excel(\n",
    "#     medical_answers_path + \"Resultados_Anotacoes_Teste_Progresso-DPOC-Fernando.xlsx\",\n",
    "#     index=False\n",
    "# )\n",
    "# df_iam.to_excel(\n",
    "#     medical_answers_path + \"Resultados_Anotacoes_Teste_Progresso-IAM-Fernando.xlsx\",\n",
    "#     index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51494a3",
   "metadata": {},
   "source": [
    "After that, a manual phase was conducted to filter out meaningless answers (such as \"Não quero responder\")\n",
    "\n",
    "### DPOC:\n",
    "\n",
    "#### Não foi removida mas é interessante trackear\n",
    "* 9001000\t76946666-fca1-49ac-aef1-23d6bea602bd --> \"Ainda não aprendi sobre doença pulonar obstrutiva crônica no curso de Medicina. Sobre DPOC, apenas sei que se trata de várias doenças que dificultam o fluxo de ar no pulmão, de modo que a respiração seja afetada.\"\n",
    "* 9004190\tae0e68aa-78ab-4ad8-8463-342c5ac1c00e --> \"fumantes\"\n",
    "\n",
    "#### Removidos:\n",
    "* 5000254\t2fd88eb0-3274-4b2c-a5a7-7957bbbe528b\n",
    "* 5000548\tec425274-fd02-4620-8a81-24db41f5cc22\n",
    "* 5000556\t8396380d-e0b6-4b81-8fe9-0b99c611f9f3\n",
    "* 7000529\t337411a4-d8c4-47dc-acfc-9d72b43d2abf\n",
    "\n",
    "\n",
    "### IAM:\n",
    "_All data was removed by the automatic sanitization_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0e4a1",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd8660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dpoc rows (included): 432\n",
      "df_iam rows (included): 447\n"
     ]
    }
   ],
   "source": [
    "# Filter DataFrames to include only rows marked for analysis\n",
    "df_dpoc = df_dpoc[df_dpoc.get(\"include_in_analysis\", 0) == 1].reset_index(drop=True)\n",
    "df_iam = df_iam[df_iam.get(\"include_in_analysis\", 0) == 1].reset_index(drop=True)\n",
    "\n",
    "print(\"df_dpoc rows (included):\", len(df_dpoc))\n",
    "print(\"df_iam rows (included):\", len(df_iam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a35e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the target columns\n",
    "\n",
    "# user id ==> identificador único do aluno\n",
    "# objective test score ==> nota obtida pelos alunos no OSCE (Objective Structured Clinical Examination)\n",
    "# question 2, question ==> resposta da questão dissertativa\n",
    "# global score ==> nota global dada à resposta\n",
    "\n",
    "target_columns_dpoc = [\"user id\", \"objective test score\", \"question 2\", \"global score\"]\n",
    "target_columns_iam = [\"user id\", \"objective test score\", \"question\", \"global score\"]\n",
    "\n",
    "df_dpoc = df_dpoc[target_columns_dpoc]\n",
    "df_iam = df_iam[target_columns_iam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d27b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns before merging\n",
    "df_dpoc = df_dpoc.rename(columns={\"question 2\": \"dpoc_answers\", \"global score\": \"dpoc_global_score\"})\n",
    "df_iam = df_iam.rename(columns={\"question\": \"iam_answers\", \"global score\": \"iam_global_score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9fc0d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dpoc rows: 432\n",
      "df_iam rows: 447\n"
     ]
    }
   ],
   "source": [
    "# Final length of each DataFrame\n",
    "get_dataframe_len(df_dpoc, df_iam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c58d9",
   "metadata": {},
   "source": [
    "## Converting the Dataset to HuggingFace Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e25d2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a DataFrame to a Huggingface Dataset with top and bottom scoring samples\n",
    "def get_huggingface_dataset(df, sample_percentage, answer_column, scrore_column):\n",
    "\n",
    "  # Select only answer relevant columns\n",
    "  subset = df[[answer_column, scrore_column]].copy()\n",
    "\n",
    "  # Order by score\n",
    "  subset = subset.sort_values(by=scrore_column).reset_index(drop=True)\n",
    "\n",
    "  # Calculate indices for top and bottom samples\n",
    "  subset_len = len(subset)\n",
    "  n = int(subset_len * sample_percentage)\n",
    "\n",
    "  # Assign labels\n",
    "  labels = np.full(subset_len, 'middle', dtype=object)\n",
    "  labels[:n] = 'bottom'\n",
    "  labels[-n:] = 'top'\n",
    "  subset['label'] = labels\n",
    "\n",
    "  # Remove middle samples\n",
    "  subset = subset[subset['label'] != 'middle'].reset_index(drop=True)\n",
    "\n",
    "  # Remove score column\n",
    "  subset = subset.drop(columns=[scrore_column])\n",
    "\n",
    "  # Rename answer column to text\n",
    "  subset = subset.rename(columns={answer_column: 'text'})\n",
    "\n",
    "  # Convert to Huggingface Dataset\n",
    "  hf_dataset = Dataset.from_pandas(subset)\n",
    "\n",
    "  # Convert label column to ClassLabel\n",
    "  unique_labels = hf_dataset.unique('label')\n",
    "  class_label = ClassLabel(names=[str(l) for l in unique_labels])\n",
    "  hf_dataset = hf_dataset.cast_column('label', class_label)\n",
    "\n",
    "  return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b86da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████| 258/258 [00:00<00:00, 43188.48 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 258/258 [00:00<00:00, 83886.08 examples/s] \n",
      "Casting the dataset: 100%|██████████| 268/268 [00:00<00:00, 159307.46 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 268/268 [00:00<00:00, 89846.81 examples/s] \n"
     ]
    }
   ],
   "source": [
    "for answer_type in ['dpoc', 'iam']:\n",
    "\n",
    "    df = {\"dpoc\": df_dpoc, \"iam\": df_iam}[answer_type]\n",
    "    \n",
    "    # Convert to Huggingface Dataset\n",
    "    hf_dataset = get_huggingface_dataset(df, 0.3, f'{answer_type}_answers', f'{answer_type}_global_score')\n",
    "    \n",
    "    # Save the Huggingface Dataset to disk\n",
    "    hf_dataset.save_to_disk(f\"{medical_answers_path}/{answer_type}_hf_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6d9db",
   "metadata": {},
   "source": [
    "# Extract Activation Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf8c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "GRID_SIZES = [10, 20, 30, 40, 50]\n",
    "SAMPLE_SIZE = 1000\n",
    "model_ckpt = \"neuralmind/bert-base-portuguese-cased\" # The same used in the article\n",
    "\n",
    "medical_answers_data_path = \"../data/medical_answers/\"\n",
    "processed_graphs_path = f\"{medical_answers_data_path}processed/graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2274a278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open each Huggingface Dataset\n",
    "dpoc_dataset = load_from_disk(f\"{medical_answers_path}/dpoc_hf_dataset\")\n",
    "dpoc_dataset.cleanup_cache_files()\n",
    "\n",
    "iam_dataset = load_from_disk(f\"{medical_answers_path}/iam_hf_dataset\")\n",
    "iam_dataset.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d82fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for answer_type in [\"dpoc\", \"iam\"]:\n",
    "    dataset = {\"dpoc\": dpoc_dataset, \"iam\": iam_dataset}[answer_type]\n",
    "    for sample in range(SAMPLE_SIZE):\n",
    "        print(f\"Processing {answer_type} sample {sample+1}/{SAMPLE_SIZE}\")\n",
    "        for grid_size in GRID_SIZES:\n",
    "\n",
    "            umap = UMAP(n_components=2, random_state=42, gridsize=grid_size)\n",
    "\n",
    "            llm_mri = ActivationAreas(\n",
    "                model=model_ckpt, device=\"cpu\", dataset=dataset, reduction_method=umap\n",
    "            )\n",
    "            llm_mri.process_activation_areas()\n",
    "\n",
    "            g_top = llm_mri.get_graph(\"top\")\n",
    "            g_bottom = llm_mri.get_graph(\"bottom\")\n",
    "\n",
    "            nx.write_gexf(\n",
    "                g_top,\n",
    "                f\"{processed_graphs_path}/{answer_type}/{grid_size}/g_top_{sample}.gexf\",\n",
    "            )\n",
    "            nx.write_gexf(\n",
    "                g_bottom,\n",
    "                f\"{processed_graphs_path}/{answer_type}/{grid_size}/g_bottom_{sample}.gexf\",\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
